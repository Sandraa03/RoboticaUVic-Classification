{
 "metadata": {
  "name": "",
  "signature": "sha256:0ae62876fad2e9ed82a2f56e7372b76dff479d411f3e7a661916d5e19782a602"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy.spatial.distance as dist\n",
      "from sklearn.metrics import accuracy_score\n",
      "from collections import Counter\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import pylab as pl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "K-Nearest Neighbors"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Q1 Implement a function that does kNN classification, and use it to classify the Iris dataset. Once you get a near-perfect classification there, use your function in the 3DClothing dataset. Plot the accuracy for all odd values of k from 1 to 9.\n",
      "\n",
      "        Hint: the cdist function in SciPy may be helpful.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = np.array([map(float, x.split(',')[:-1]) for x in open('iris.data') if x.strip()!=''])\n",
      "labels = np.array([x.split(',')[-1].strip() for x in open('iris.data') if x.strip()!=''])\n",
      "\n",
      "idx_train = np.loadtxt('iris_idx_train.txt')\n",
      "idx_test = np.loadtxt('iris_idx_test.txt')\n",
      "\n",
      "idx_train = idx_train.astype(int)\n",
      "idx_test = idx_test.astype(int)\n",
      "\n",
      "data_training = data[idx_train,:]\n",
      "data_testing = data[idx_test,:]\n",
      "labels_training = labels[idx_train]\n",
      "labels_testing = labels[idx_test]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def kNN(data_training, data_testing, labels_training, labels_testing):\n",
      "    for i in range(1,9):\n",
      "        distance = dist.cdist(data_training, data_testing)\n",
      "        min_k = np.argsort(distance.T,1)[:,1:i+1]\n",
      "        min_labels = labels_training[min_k]\n",
      "        accuracy = accuracy_score(labels_testing, [Counter(x).most_common()[0][0] for x in min_labels] )\n",
      "        print accuracy\n",
      "\n",
      "kNN (data_training, data_testing, labels_training, labels_testing)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.94\n",
        "0.94\n",
        "0.94\n",
        "0.94\n",
        "0.96\n",
        "0.96\n",
        "0.96\n",
        "0.94\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Logistic Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Q2 First we will focus on a two-class problem. Use slicing to get a new training and testing set that only contains the instances corresponding to shirt and jeans (remember to also create new label variables!). Then, train a Logistic Regression classifier, adjusting the C parameter with cross-validation. This time you can chose to use the cross-validation functions provided by sklearn. Plot the training and validation accuracy as C is incresed, and print the test accuracy for the selected model.\n",
      "\n",
      "    Let your C search range be from 10^-7 to 10^7.\n",
      "    Hint: use log-scale for the C value in the plot. Hint: Since we do not have a lot of training data, use 15 folds to ensure the train set will be large enough.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "A = list(range(1, 16))\n",
      "B = list(range(1, 16))\n",
      "p = 0\n",
      "data_training = np.load('3dclothing_train.npy')\n",
      "data_testing = np.load('3dclothing_test.npy')\n",
      "\n",
      "labels_training = np.array([x.strip() for x in open('3dclothing_labels_train.txt')])\n",
      "labels_testing = np.array([x.strip() for x in open('3dclothing_labels_test.txt')])\n",
      "\n",
      "ok_training = data_training[(labels_training == 'shirt') + (labels_training == 'jeans'),:]\n",
      "ok_testing = data_testing[(labels_testing == 'shirt') + (labels_testing == 'jeans'),:]\n",
      "\n",
      "ok_labels_training = labels_training[(labels_training == 'shirt') + (labels_training == 'jeans')]\n",
      "ok_labels_testing = labels_testing[(labels_testing == 'shirt') + (labels_testing == 'jeans')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in xrange (-7,8):    \n",
      "    LogReg = LogisticRegression(C=10**i)\n",
      "    A[p]=i\n",
      "    LogReg.fit(ok_training, ok_labels_training)\n",
      "    B[p] = LogReg.score(ok_testing, ok_labels_testing)\n",
      "    print 'Logistic Regression accuracy for C = 10^', i, ' is ', B[p]\n",
      "    p+=1\n",
      "\n",
      "pl.plot(A[:14],B[:14])\n",
      "\n",
      "pl.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Logistic Regression accuracy for C = 10^ -7  is  0.61038961039\n",
        "Logistic Regression accuracy for C = 10^ -6  is  0.688311688312\n",
        "Logistic Regression accuracy for C = 10^ -5  is  0.766233766234\n",
        "Logistic Regression accuracy for C = 10^ -4  is  0.883116883117\n",
        "Logistic Regression accuracy for C = 10^ -3  is  0.883116883117\n",
        "Logistic Regression accuracy for C = 10^ -2  is  0.857142857143\n",
        "Logistic Regression accuracy for C = 10^"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -1  is  0.818181818182\n",
        "Logistic Regression accuracy for C = 10^ 0  is  0.831168831169\n",
        "Logistic Regression accuracy for C = 10^ 1  is  0.844155844156\n",
        "Logistic Regression accuracy for C = 10^ 2  is  0.831168831169\n",
        "Logistic Regression accuracy for C = 10^ 3  is  0.831168831169\n",
        "Logistic Regression accuracy for C = 10^"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4  is  0.831168831169\n",
        "Logistic Regression accuracy for C = 10^ 5  is  0.831168831169\n",
        "Logistic Regression accuracy for C = 10^ 6  is  0.831168831169\n",
        "Logistic Regression accuracy for C = 10^ 7  is  0.831168831169\n"
       ]
      }
     ],
     "prompt_number": 79
    }
   ],
   "metadata": {}
  }
 ]
}